{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "punctuation = string.punctuation\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spamdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here ham means, its not a spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we have to remove noise,  unnecessary redundent information present. Let's clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean(text):\n",
    "    \n",
    "    cleaned_text = text.lower()\n",
    "    cleaned_text = \"\".join(c for c in cleaned_text if c not in punctuation)\n",
    "    \n",
    "    words = cleaned_text.split()\n",
    "    words = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    words = [lem.lemmatize(word, \"v\") for word in words]\n",
    "    words = [lem.lemmatize(word, \"n\") for word in words]\n",
    "\n",
    "    \n",
    "    cleaned_text = \" \".join(words)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play game today'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_clean(\"I will be playing a game today !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " data['cleaned'] = data['text'].apply(_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think go usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                u dun say early hor u c already say  \n",
       "4           nah dont think go usf live around though  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_counts'] = data['text'].apply(lambda x : len(x.split()))\n",
    "data['word_count_cleaned'] = data['cleaned'].apply(lambda x : len(x.split()))\n",
    "\n",
    "data['char_counts'] = data['text'].apply(lambda x : len(x))\n",
    "data['char_counts_without_spaces'] = data['text'].apply(lambda x : len(x.replace(\" \", \"\")))\n",
    "\n",
    "data['num_digits'] = data['text'].apply(lambda x : sum([1 if w.isdigit() else 0 for w in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>char_counts_without_spaces</th>\n",
       "      <th>num_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think go usf live around though</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  word_counts  \\\n",
       "0  go jurong point crazy available bugis n great ...           20   \n",
       "1                              ok lar joke wif u oni            6   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...           28   \n",
       "3                u dun say early hor u c already say           11   \n",
       "4           nah dont think go usf live around though           13   \n",
       "\n",
       "   word_count_cleaned  char_counts  char_counts_without_spaces  num_digits  \n",
       "0                  16          111                          92           0  \n",
       "1                   6           29                          24           0  \n",
       "2                  23          155                         128           2  \n",
       "3                   9           49                          39           0  \n",
       "4                   8           61                          49           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {\"noun\" : [\"NNP\", \"NN\", \"NNS\", \"NNPS\"], \"verb\": [\"VB\", \"VBZ\", \"VBD\", \"VBN\", \"VBG\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "def pos_count(text, family):\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    count = 0\n",
    "    for tag in tags:\n",
    "        tag = tag[1]\n",
    "        if tag in pos_dict[family]:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_count(\"They are playing in the ground\", \"verb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"noun_count\"] = data[\"text\"].apply(lambda x : pos_count(x, \"noun\"))\n",
    "data[\"verb_count\"] = data[\"text\"].apply(lambda x : pos_count(x, \"verb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>char_counts_without_spaces</th>\n",
       "      <th>num_digits</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think go usf live around though</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  word_counts  \\\n",
       "0  go jurong point crazy available bugis n great ...           20   \n",
       "1                              ok lar joke wif u oni            6   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...           28   \n",
       "3                u dun say early hor u c already say           11   \n",
       "4           nah dont think go usf live around though           13   \n",
       "\n",
       "   word_count_cleaned  char_counts  char_counts_without_spaces  num_digits  \\\n",
       "0                  16          111                          92           0   \n",
       "1                   6           29                          24           0   \n",
       "2                  23          155                         128           2   \n",
       "3                   9           49                          39           0   \n",
       "4                   8           61                          49           0   \n",
       "\n",
       "   noun_count  verb_count  \n",
       "0          10           1  \n",
       "1           4           0  \n",
       "2          13           3  \n",
       "3           3           0  \n",
       "4           1           4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvz = CountVectorizer()\n",
    "cvz.fit(data['cleaned'].values)\n",
    "count_vectors = cvz.transform(data['cleaned'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8207 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 46862 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating word count, ngram cound, character count and their respective TFIDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word level\n",
    "word_tfidf = TfidfVectorizer(max_features = 500)\n",
    "word_tfidf.fit(data[\"cleaned\"].values)\n",
    "word_vectors_tfidf = word_tfidf.transform(data['cleaned'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram level\n",
    "ngram_tfidf = TfidfVectorizer(max_features = 500, ngram_range = (1, 2))\n",
    "ngram_tfidf.fit(data[\"cleaned\"].values)\n",
    "ngram_vectors_tfidf = ngram_tfidf.transform(data['cleaned'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char level\n",
    "char_tfidf = TfidfVectorizer(max_features = 500, analyzer = \"char\")\n",
    "char_tfidf.fit(data[\"cleaned\"].values)\n",
    "char_vectors_tfidf = char_tfidf.transform(data['cleaned'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.629957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.936809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5.754488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5.888019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150p</th>\n",
       "      <td>6.406813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150ppm</th>\n",
       "      <td>6.070341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.693863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.841499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st</th>\n",
       "      <td>6.014771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>5.988103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>6.581166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd</th>\n",
       "      <td>6.191702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>5.797047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>6.406813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>6.629957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>6.490195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>6.792475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86688</th>\n",
       "      <td>6.629957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>6.329852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abt</th>\n",
       "      <td>6.406813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>5.962127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actually</th>\n",
       "      <td>6.129181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>6.534646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aft</th>\n",
       "      <td>6.629957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afternoon</th>\n",
       "      <td>6.258393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>6.735317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ah</th>\n",
       "      <td>6.191702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aight</th>\n",
       "      <td>6.099328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>already</th>\n",
       "      <td>5.137052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alright</th>\n",
       "      <td>6.447635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whats</th>\n",
       "      <td>6.099328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wid</th>\n",
       "      <td>6.581166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wif</th>\n",
       "      <td>6.329852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wife</th>\n",
       "      <td>6.681250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wil</th>\n",
       "      <td>6.681250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win</th>\n",
       "      <td>5.268980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>5.451302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without</th>\n",
       "      <td>6.490195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk</th>\n",
       "      <td>6.490195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonder</th>\n",
       "      <td>6.406813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>5.636705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>5.618356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>4.765876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>6.070341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worry</th>\n",
       "      <td>5.936809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wot</th>\n",
       "      <td>6.490195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>5.377194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmas</th>\n",
       "      <td>6.490195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xxx</th>\n",
       "      <td>6.129181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>5.733868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>5.171341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>5.335229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>5.159781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesterday</th>\n",
       "      <td>6.447635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet</th>\n",
       "      <td>5.713666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yo</th>\n",
       "      <td>6.099328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youre</th>\n",
       "      <td>5.655397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr</th>\n",
       "      <td>6.581166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yup</th>\n",
       "      <td>5.841499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ìï</th>\n",
       "      <td>5.713666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_tfidf\n",
       "10           6.629957\n",
       "100          5.936809\n",
       "1000         5.754488\n",
       "150          5.888019\n",
       "150p         6.406813\n",
       "150ppm       6.070341\n",
       "16           5.693863\n",
       "18           5.841499\n",
       "1st          6.014771\n",
       "2000         5.988103\n",
       "250          6.581166\n",
       "2nd          6.191702\n",
       "500          5.797047\n",
       "5000         6.406813\n",
       "750          6.629957\n",
       "800          6.490195\n",
       "8007         6.792475\n",
       "86688        6.629957\n",
       "able         6.329852\n",
       "abt          6.406813\n",
       "account      5.962127\n",
       "actually     6.129181\n",
       "address      6.534646\n",
       "aft          6.629957\n",
       "afternoon    6.258393\n",
       "age          6.735317\n",
       "ah           6.191702\n",
       "aight        6.099328\n",
       "already      5.137052\n",
       "alright      6.447635\n",
       "...               ...\n",
       "whats        6.099328\n",
       "wid          6.581166\n",
       "wif          6.329852\n",
       "wife         6.681250\n",
       "wil          6.681250\n",
       "win          5.268980\n",
       "wish         5.451302\n",
       "without      6.490195\n",
       "wk           6.490195\n",
       "wonder       6.406813\n",
       "wont         5.636705\n",
       "word         5.618356\n",
       "work         4.765876\n",
       "world        6.070341\n",
       "worry        5.936809\n",
       "wot          6.490195\n",
       "would        5.377194\n",
       "xmas         6.490195\n",
       "xxx          6.129181\n",
       "ya           5.733868\n",
       "yeah         5.171341\n",
       "year         5.335229\n",
       "yes          5.159781\n",
       "yesterday    6.447635\n",
       "yet          5.713666\n",
       "yo           6.099328\n",
       "youre        5.655397\n",
       "yr           6.581166\n",
       "yup          5.841499\n",
       "ìï           5.713666\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = dict(zip(word_tfidf.get_feature_names(), word_tfidf.idf_))\n",
    "tfidf_idf = pd.DataFrame(columns = [\"word_tfidf\"]).from_dict(tfidf, orient = \"index\")\n",
    "tfidf_idf.columns=[\"word_tfidf\"]\n",
    "tfidf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text', 'cleaned', 'word_counts', 'word_count_cleaned',\n",
       "       'char_counts', 'char_counts_without_spaces', 'num_digits', 'noun_count',\n",
       "       'verb_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x507 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 61715 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_features = ['word_counts', 'word_count_cleaned',\n",
    "       'char_counts', 'char_counts_without_spaces', 'num_digits', 'noun_count',\n",
    "       'verb_count']\n",
    "\n",
    "feature_set1 = data[meta_features]\n",
    "\n",
    "train = hstack([word_vectors_tfidf, csr_matrix(feature_set1)], \"csr\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical data into label encoded one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = data[\"label\"].values\n",
    "target = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dividing into training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 507)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393, 507)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9727207465900933"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(train_x, train_y)\n",
    "pred = model.predict(val_x)\n",
    "accuracy_score(pred, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubhamsingh/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9763101220387652"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_x, train_y)\n",
    "pred = model.predict(val_x)\n",
    "accuracy_score(pred, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubhamsingh/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9346733668341709"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_x, train_y)\n",
    "pred = model.predict(val_x)\n",
    "accuracy_score(pred, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubhamsingh/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9806173725771715"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ensemble.ExtraTreesClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "pred = model.predict(val_x)\n",
    "accuracy_score(pred, val_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
